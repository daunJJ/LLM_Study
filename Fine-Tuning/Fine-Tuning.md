## LLM Fine-Tuning

### Fine-Tuning이란?

**특정 작업이나 도메인에 높은 적합성**을 확보하기 위해, 이미 훈련된 대규모 언어 모델에 **특정 데이터셋을 사용하여 추가적인 학습을 수행하는 작업**

### 전이학습 vs 파인튜닝

- 전이 학습은 이미 학습된 모델의 일부 또는 전체를 새로운 작업에 재사용하는 것
- 파인튜닝은 전이학습의 일부로서, 전이학습된 모델을 새로운 작업에 맞게 조정하는 과정

| 구 분 | 전이학습(Transfer Learning) | 파인튜닝(Fine-Tuning) |
| --- | --- | --- |
| 목적 | 대규모 데이터셋에서 학습된 지식을 새로운 작업에 적용 | 사전 훈련된 모델을 특정 작업에 맞추어 추가 조정 |
| 핵심 과정 | 기존 모델의 지식을 새로운 문제에 전달 | 기존 모델의 세부 사항을 새로운 문제에 최적화 |
| 학습 순서 | 사전 훈련된 모델 인스턴스화 → 기존 모델의 상위 층 동결 → 새로운 출력 층 추가 → 새로운 데이터셋으로 훈련 → 전체 모델의 미세 조정 | 사전 훈련된 모델의 초기 가중치 활용 → 파라미터 조정과 재학습 → 학습률 조절  |
| 데이터 요구량 | 상대적으로 적음 | 상대적으로 적으나, 모델을 특정 작업에 맞게 조정 필요 |
| 적용 예시 | ImageNet으로 학습된 모델을 특정 동식물 분류에 적용 | 의료 영상 분석을 위해 일반 이미지 분류 모델을 조정 |
| 학습시간 | 새로운 학습보다 단축 | 사전 훈련된 모델을 기반으로 하므로 단축 |
| 적합성 | 다양한 작업에 일반적인 모델 적용 가능 | 매우 특정한 작업이나 데이터셋에 최적화 필요 |

### Fine-Tuning의 방법
<img src="https://github.com/daunJJ/LLM_Study/assets/109944763/dff5993c-5f26-419b-b512-9ffeb8cc61f9" width="400"/>

- Full Fine-tuning
    - 모든 모델 매개변수를 포함하여 사전 학습된 모델 전체를 파인튜닝하는 작업
    - 사전 학습된 모델의 모든 레이어와 매개 변수가 업데이트되고 최적화되어 대상 작업의 요구 사항에 맞게 조정
    - 사전 학습된 모델 사이에 큰 차이가 있거나 작업에서 모델의 유연성과 적응성이 높아야 하는 경우에 적합
    - 상당한 리소스와 시간이 필요하지만 그만큼 더 나은 성능을 얻을 수 있음
- Repurposing
    - 사전 학습된 모델의 하위 레이어를 그대로 유지하면서 모델의 상위 레이어 또는 선택된 몇 개의 레이어를 파인튜닝하는 것
    - 사전 학습된 모델에 대한 일반적인 지식을 유지하면서 최상위 레이어를 특정 작업에 적용하는 것
    - 대상 작업과 사전 학습된 모델 사이에 특정 유사성이 있거나 작업 데이터셋이 작은 경우에 적합
    - 필요한 리소스와 시간이 적지만 경우에 따라 약간의 성능 저하가 발생

### Task이 성격에 따른 Fine-Tuning 전략

1. 우리 데이터셋이 크고, 유사성이 작다
    - Pre-trained model의 전체 레이어 학습
2. 우리 데이터셋이 크고, 유사성이 크다
    - Pre-trained model의 레이어 일부분과 classfier를 학습
3. 우리 데이터셋이 작고, 유사성이 작다
    - Pre-trained model의 레이어 일부분과 classfier를 학습
4. 우리 데이터셋이 작고, 유사성이 크다
    - 최종 Classifier의 FC Layer만 학습

### Fine-Tuning 유형

1. Supevised Fine-tuning
    - 파인 튜닝 단계에서 레이블이 지정된 학습 데이터셋을 사용하는 프로세스
    - 레이블은 파인튜닝 중에 모델에 대한 목표 출력을 제공
    - 보통 각 샘플에 관련 레이블이 있는 분류 데이터셋과 같은 작업별 레이블이 지정된 데이터셋이 사용
2. Unsupervised Fine-tuning
    - 파인 튜닝 단계에서 레이블이 지정되지 않은 학습 데이터셋을 사용하는 프로세스
    - 명시적인 목표 출력 없이 입력 데이터 자체에 있는 정보에만 의존할 수 있음
    - 유용한 기능을 추출하거나 모델의 표현 기능을 향상하는 것을 목표로 데이터의 고유 구조를 활용하거나 데이터를 생성
  
## PEFT(Parameter-Efficient Fine-Tuning)

### 배경

- GPT와 같은 LLM은 학습에 쓰이는 GPU 메모리의 양이 크고 파라미터의 갯수가 매우 큼
- 따라서 이를 줄이기 위한 방법을 고안

### PEFT란?

- 모델의 모든 매개변수를 미세조정하지 않고도 사전훈련된 LLM을 다양한 하위 작업에 효과적으로 적응 시키는 것으 도움
- 소수의 모델 매개변수만을 fine-tuning하여 계산 및 저장 비용 감소
- 전체 미세조정의 성능과 비교할 수 있는 성능 달성

### PEFT가 지원하는 모델

- LoRA, Prefix Tuning, P-Tuning, Prompt Tuning, AdaLoRA, (lA)^3, MultiTask Prompt Tuning
