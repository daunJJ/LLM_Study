<h1 align="center"> ğŸ’¬ LLM_Study </h1>
<h4 align="center"> 2024 ìƒë°˜ê¸° LLM ìŠ¤í„°ë”” </h4>

## Introduction
* ì£¼ì œ: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì´í•´ 
* ìŠ¤í„°ë”” ê¸°ê°„: 2024.02 ~ 2024.06

## Contents
#### ë”¥ëŸ¬ë‹ ê¸°ë°˜ ê¸°ê³„ ë²ˆì—­ ëª¨ë¸ í•™ìŠµ

1. RNN
    - [ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…](https://github.com/daunJJ/LLM_Study/blob/main/RNN/DeepLearningBase.md)
    - [RNN ê¸°ë³¸ êµ¬ì¡°](https://github.com/daunJJ/LLM_Study/blob/main/RNN/RNN.md)
2. Seq2Seq 
    - [Seq2Seq ê¸°ë³¸ êµ¬ì¡°](https://github.com/daunJJ/LLM_Study/blob/main/Seq2Seq/Seq2Seq.md)
3. Transformer 
    - [Transformer ê¸°ë³¸ êµ¬ì¡°](https://github.com/daunJJ/LLM_Study/blob/main/Transformer/Transformer.md)
    - [Transformer êµ¬í˜„ ì½”ë“œ](https://github.com/daunJJ/LLM_Study/blob/main/Transformer/Transformer_GermantoEnglish_example.ipynb)

#### ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ LLM í•™ìŠµ

1. LLM ë…¼ë¬¸ ë¦¬ë·°
    - Llama
        - [Llama1 ë…¼ë¬¸ ë¦¬ë·°](https://github.com/daunJJ/LLM_Study/blob/main/LLM/Llama1.md) / [Llama2 ë…¼ë¬¸ ë¦¬ë·°](https://github.com/daunJJ/LLM_Study/blob/main/LLM/Llama2.md)
    - Alpaca
        - [Alpaca ë…¼ë¬¸ ë¦¬ë·°](https://github.com/daunJJ/LLM_Study/blob/main/LLM/Alpaca.md)
    - GPT
        - [GPT1 ë…¼ë¬¸ ë¦¬ë·°](https://github.com/daunJJ/LLM_Study/blob/main/LLM/GPT1.md) / [GPT2 ë…¼ë¬¸ ë¦¬ë·°](https://github.com/daunJJ/LLM_Study/blob/main/LLM/GPT2.md) / [GPT3 ë…¼ë¬¸ ë¦¬ë·°](https://github.com/daunJJ/LLM_Study/blob/main/LLM/GPT3.md)
2. Fine-Tuning ê¸°ë²•
    - [Fine-Tuning ê¸°ë³¸ ê°œë…](https://github.com/daunJJ/LLM_Study/blob/main/Fine-Tuning/Fine-Tuning.md)
    - PEFT ê¸°ë³¸ ê°œë…
        - [LoRA](https://github.com/daunJJ/LLM_Study/blob/main/Fine-Tuning/PEFT_LoRA.md) / [Prefix-Tuning](https://github.com/daunJJ/LLM_Study/blob/main/Fine-Tuning/PEFT_Prefix-Tuning.md) / [P-Tuning](https://github.com/daunJJ/LLM_Study/blob/main/Fine-Tuning/PEFT_P-Tuning.md) / [Prompt-Tuning](https://github.com/daunJJ/LLM_Study/blob/main/Fine-Tuning/PEFT_Prompt-Tuning.md)
    - PEFT ì‹¤ìŠµ
        - [LoRA](https://github.com/daunJJ/LLM_Study/blob/main/Fine-Tuning/PEFT_LoRA_token_classification_example.ipynb) / [Prefix-Tuning](https://github.com/daunJJ/LLM_Study/blob/main/Fine-Tuning/PEFT_Prefix-Tuning_sentiment_classification_example.ipynb) / [P-Tuning](https://github.com/daunJJ/LLM_Study/blob/main/Fine-Tuning/PEFT_P-Tuning_semantic_similarity_example.ipynb) / [Prompt-Tuning](https://github.com/daunJJ/LLM_Study/blob/main/Fine-Tuning/PEFT_Prompt-Tuning_casual_language_modeling_example.ipynb)
3. Prompt Engieerning ê¸°ë²• 
    - [CoT ê¸°ë³¸ ê°œë…](https://github.com/daunJJ/LLM_Study/blob/main/Prompt-Engineering/CoT(Chain-of-Thought).md)
